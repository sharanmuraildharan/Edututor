{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEpPIIOZnxVZ",
        "outputId": "9aae80bb-0d13-44e0-e8cd-1e9e845f7a93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.44.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.56.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.10.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Collecting pypdf2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting python-pptx\n",
            "  Downloading python_pptx-1.0.2-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (4.13.5)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.12/dist-packages (0.8.5)\n",
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.10.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.116.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (0.6.1)\n",
            "Requirement already satisfied: gradio-client==1.12.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.12.1)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.34.4)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.11.7)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.12.11)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.47.3)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.17.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.15.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.35.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.12.1->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.12.1->gradio) (15.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.8.3)\n",
            "Collecting XlsxWriter>=0.5.7 (from python-pptx)\n",
            "  Downloading xlsxwriter-3.2.5-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from python-pptx) (5.4.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (2.8)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.25.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.181.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from langdetect) (1.17.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (1.1.9)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.30.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.74.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_pptx-1.0.2-py3-none-any.whl (472 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.8/472.8 kB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xlsxwriter-3.2.5-py3-none-any.whl (172 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.3/172.3 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993223 sha256=1febb20bac89acd47ca2de29d114284549712487f845bdbf7fc744bef7c333ce\n",
            "  Stored in directory: /root/.cache/pip/wheels/c1/67/88/e844b5b022812e15a52e4eaa38a1e709e99f06f6639d7e3ba7\n",
            "Successfully built langdetect\n",
            "Installing collected packages: XlsxWriter, pypdf2, langdetect, python-pptx\n",
            "Successfully installed XlsxWriter-3.2.5 langdetect-1.0.9 pypdf2-3.0.1 python-pptx-1.0.2\n"
          ]
        }
      ],
      "source": [
        "!pip install gradio transformers torch accelerate requests pypdf2 python-pptx beautifulsoup4 google-generativeai langdetect\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Educational AI Assistant - Device Fixed + Dynamic Interface\n",
        "# Run this in Google Colab\n",
        "\n",
        "# Install required packages\n",
        "!pip install gradio transformers torch accelerate requests pypdf2 python-pptx beautifulsoup4 google-generativeai langdetect\n",
        "\n",
        "import gradio as gr\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import google.generativeai as genai\n",
        "import os\n",
        "import requests\n",
        "from PyPDF2 import PdfReader\n",
        "from pptx import Presentation\n",
        "from bs4 import BeautifulSoup\n",
        "from langdetect import detect\n",
        "import json\n",
        "import re\n",
        "from datetime import datetime\n",
        "import time\n",
        "\n",
        "# Configuration\n",
        "class Config:\n",
        "    granite_model = \"ibm-granite/granite-3.3-2b-instruct\"\n",
        "    gemini_model = \"gemini-2.5-flash-image-preview\"\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Initialize models with proper device handling\n",
        "def initialize_models(gemini_api_key):\n",
        "    \"\"\"Initialize both Granite and Gemini models with proper device handling\"\"\"\n",
        "    try:\n",
        "        # Initialize Granite model with proper device handling\n",
        "        print(f\"Loading AI models on {Config.device}...\")\n",
        "        tokenizer = AutoTokenizer.from_pretrained(Config.granite_model, trust_remote_code=True)\n",
        "\n",
        "        # Add padding token if it doesn't exist\n",
        "        if tokenizer.pad_token is None:\n",
        "            tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "        model = AutoModelForCausalLM.from_pretrained(\n",
        "            Config.granite_model,\n",
        "            torch_dtype=torch.float16 if Config.device == \"cuda\" else torch.float32,\n",
        "            device_map=\"auto\" if Config.device == \"cuda\" else None,\n",
        "            trust_remote_code=True,\n",
        "            low_cpu_mem_usage=True\n",
        "        )\n",
        "\n",
        "        # Explicitly move model to device if not using device_map\n",
        "        if Config.device == \"cpu\":\n",
        "            model = model.to(Config.device)\n",
        "\n",
        "        # Initialize Gemini\n",
        "        genai.configure(api_key=gemini_api_key)\n",
        "        gemini_model = genai.GenerativeModel(Config.gemini_model)\n",
        "\n",
        "        return tokenizer, model, gemini_model, f\"Ready! Models loaded on {Config.device}. AI assistant is now active.\"\n",
        "    except Exception as e:\n",
        "        return None, None, None, f\"Setup failed: {str(e)}\"\n",
        "\n",
        "# File processing functions\n",
        "def extract_text_from_pdf(file_path):\n",
        "    try:\n",
        "        reader = PdfReader(file_path)\n",
        "        text = \"\"\n",
        "        for page in reader.pages:\n",
        "            text += page.extract_text() + \"\\n\"\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        return f\"Error reading PDF: {str(e)}\"\n",
        "\n",
        "def extract_text_from_pptx(file_path):\n",
        "    try:\n",
        "        prs = Presentation(file_path)\n",
        "        text = \"\"\n",
        "        for slide in prs.slides:\n",
        "            for shape in slide.shapes:\n",
        "                if hasattr(shape, \"text\"):\n",
        "                    text += shape.text + \"\\n\"\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        return f\"Error reading PPTX: {str(e)}\"\n",
        "\n",
        "def extract_text_from_url(url):\n",
        "    try:\n",
        "        headers = {\n",
        "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'\n",
        "        }\n",
        "        response = requests.get(url, headers=headers, timeout=10)\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "        for script in soup([\"script\", \"style\"]):\n",
        "            script.decompose()\n",
        "        text = soup.get_text()\n",
        "        return ' '.join(text.split())\n",
        "    except Exception as e:\n",
        "        return f\"Error reading URL: {str(e)}\"\n",
        "\n",
        "def process_file(file, url_input):\n",
        "    if file is not None:\n",
        "        file_path = file.name\n",
        "        if file_path.endswith('.pdf'):\n",
        "            return extract_text_from_pdf(file_path)\n",
        "        elif file_path.endswith('.pptx'):\n",
        "            return extract_text_from_pptx(file_path)\n",
        "        elif file_path.endswith('.txt'):\n",
        "            with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                return f.read()\n",
        "        else:\n",
        "            return \"Please upload PDF, PPTX, or TXT files only.\"\n",
        "    elif url_input.strip():\n",
        "        return extract_text_from_url(url_input.strip())\n",
        "    else:\n",
        "        return \"\"\n",
        "\n",
        "# AI response generation with proper device handling\n",
        "def generate_granite_response(tokenizer, model, prompt, max_length=1000):\n",
        "    try:\n",
        "        # Ensure all tensors are on the same device\n",
        "        inputs = tokenizer(\n",
        "            prompt,\n",
        "            return_tensors=\"pt\",\n",
        "            truncation=True,\n",
        "            max_length=2048,\n",
        "            padding=True\n",
        "        )\n",
        "\n",
        "        # Move inputs to the same device as model\n",
        "        inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model.generate(\n",
        "                **inputs,\n",
        "                max_new_tokens=max_length,  # Use max_new_tokens instead of max_length\n",
        "                temperature=0.7,\n",
        "                do_sample=True,\n",
        "                pad_token_id=tokenizer.pad_token_id,\n",
        "                eos_token_id=tokenizer.eos_token_id,\n",
        "                repetition_penalty=1.1,\n",
        "                no_repeat_ngram_size=3\n",
        "            )\n",
        "\n",
        "        # Decode only the new tokens\n",
        "        new_tokens = outputs[0][inputs['input_ids'].shape[1]:]\n",
        "        response = tokenizer.decode(new_tokens, skip_special_tokens=True)\n",
        "\n",
        "        return response.strip() if response.strip() else \"I apologize, but I couldn't generate a proper response. Please try rephrasing your request.\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Error generating response: {str(e)}\"\n",
        "\n",
        "def generate_flowchart(gemini_model, content):\n",
        "    try:\n",
        "        prompt = f\"\"\"\n",
        "        Create a clear, step-by-step flowchart for this content:\n",
        "\n",
        "        {content[:2000]}\n",
        "\n",
        "        Format as:\n",
        "        START → Step 1 → Decision Point? → Step 2 → END\n",
        "\n",
        "        Use simple language and clear connections.\n",
        "        \"\"\"\n",
        "\n",
        "        response = gemini_model.generate_content(prompt)\n",
        "        return response.text\n",
        "    except Exception as e:\n",
        "        return f\"Flowchart generation failed: {str(e)}\"\n",
        "\n",
        "# Enhanced AI processing function with streaming simulation\n",
        "def process_ai_request(tokenizer, model, gemini_model, content, request_type, additional_input=\"\", language=\"English\"):\n",
        "    \"\"\"Enhanced function to handle all AI requests with better prompts\"\"\"\n",
        "\n",
        "    if not content and request_type not in [\"study_plan\", \"task_management\"]:\n",
        "        return \"Please upload a file, enter a URL, or provide content first.\"\n",
        "\n",
        "    # Enhanced prompt templates\n",
        "    prompts = {\n",
        "        \"explain\": f\"\"\"\n",
        "        You are an expert educator. Explain the following content in simple, clear bullet points:\n",
        "\n",
        "        Content: {content[:3000]}\n",
        "\n",
        "        Instructions:\n",
        "        • Use simple, accessible language\n",
        "        • Break down complex concepts into digestible parts\n",
        "        • Provide practical examples where relevant\n",
        "        • Include key takeaways\n",
        "        • Make it beginner-friendly\n",
        "\n",
        "        Format your response with clear bullet points using the • symbol.\n",
        "        \"\"\",\n",
        "\n",
        "        \"questions\": f\"\"\"\n",
        "        You are a knowledgeable tutor. Based on the content provided, answer the student's question thoroughly:\n",
        "\n",
        "        Content: {content[:2500]}\n",
        "\n",
        "        Student Question: {additional_input}\n",
        "\n",
        "        Provide a comprehensive answer that:\n",
        "        • Directly addresses the question\n",
        "        • Uses examples from the content when possible\n",
        "        • Explains any technical terms\n",
        "        • Offers additional context if helpful\n",
        "        \"\"\",\n",
        "\n",
        "        \"study_plan\": f\"\"\"\n",
        "        Create a comprehensive {additional_input} study plan for the topic: {content}\n",
        "\n",
        "        Structure your plan with:\n",
        "\n",
        "        LEARNING OBJECTIVES:\n",
        "        • Clear, measurable goals\n",
        "\n",
        "        STUDY SCHEDULE:\n",
        "        • Daily/weekly breakdown\n",
        "        • Time allocations\n",
        "\n",
        "        KEY RESOURCES:\n",
        "        • Essential materials to study\n",
        "        • Recommended readings\n",
        "\n",
        "        PRACTICE ACTIVITIES:\n",
        "        • Hands-on exercises\n",
        "        • Real-world applications\n",
        "\n",
        "        ASSESSMENT METHODS:\n",
        "        • Self-evaluation techniques\n",
        "        • Progress milestones\n",
        "\n",
        "        Make it practical and actionable for the specified duration.\n",
        "        \"\"\",\n",
        "\n",
        "        \"tutor\": f\"\"\"\n",
        "        Act as a specialized virtual tutor for: {content}\n",
        "        Student's Learning Style: {additional_input}\n",
        "\n",
        "        Provide a personalized tutoring approach that includes:\n",
        "\n",
        "        TEACHING STRATEGY:\n",
        "        • Methods suited to their learning style\n",
        "        • Engagement techniques\n",
        "\n",
        "        LEARNING PATH:\n",
        "        • Step-by-step progression\n",
        "        • Key milestones\n",
        "\n",
        "        PRACTICE METHODS:\n",
        "        • Exercises tailored to learning style\n",
        "        • Interactive activities\n",
        "\n",
        "        COMMON CHALLENGES:\n",
        "        • Typical difficulties students face\n",
        "        • Strategies to overcome them\n",
        "\n",
        "        PROGRESS EVALUATION:\n",
        "        • How to measure understanding\n",
        "        • Self-assessment techniques\n",
        "        \"\"\",\n",
        "\n",
        "        \"translate\": f\"\"\"\n",
        "        Translate and explain the following content in {language}:\n",
        "\n",
        "        Content: {content[:2000]}\n",
        "\n",
        "        Provide:\n",
        "        1. Accurate translation of key concepts\n",
        "        2. Cultural context where relevant\n",
        "        3. Simple explanations in the target language\n",
        "        4. Important terminology with definitions\n",
        "\n",
        "        Make sure the explanation is clear and educational.\n",
        "        \"\"\",\n",
        "\n",
        "        \"tasks\": f\"\"\"\n",
        "        Apply the 1-3-5-7 productivity rule to organize this task efficiently:\n",
        "\n",
        "        Main Task: {content}\n",
        "\n",
        "        Organize as follows:\n",
        "\n",
        "        TOP PRIORITY (1 task):\n",
        "        • [The single most critical/urgent item that must be completed]\n",
        "\n",
        "        MEDIUM PRIORITIES (3 tasks):\n",
        "        • [Important task 1]\n",
        "        • [Important task 2]\n",
        "        • [Important task 3]\n",
        "\n",
        "        SMALL TASKS (5 tasks):\n",
        "        • [Manageable task 1]\n",
        "        • [Manageable task 2]\n",
        "        • [Manageable task 3]\n",
        "        • [Manageable task 4]\n",
        "        • [Manageable task 5]\n",
        "\n",
        "        QUICK TASKS (7 tasks):\n",
        "        • [Quick win 1]\n",
        "        • [Quick win 2]\n",
        "        • [Quick win 3]\n",
        "        • [Quick win 4]\n",
        "        • [Quick win 5]\n",
        "        • [Quick win 6]\n",
        "        • [Quick win 7]\n",
        "\n",
        "        Make each item actionable and specific.\n",
        "        \"\"\",\n",
        "\n",
        "        \"summarize\": f\"\"\"\n",
        "        Analyze and create a comprehensive summary of this content:\n",
        "\n",
        "        Content: {content[:3000]}\n",
        "\n",
        "        EXECUTIVE SUMMARY:\n",
        "        • [Brief overview in 2-3 sentences]\n",
        "\n",
        "        KEY POINTS:\n",
        "        • [Main idea 1]\n",
        "        • [Main idea 2]\n",
        "        • [Main idea 3]\n",
        "\n",
        "        IMPORTANT DETAILS:\n",
        "        • [Critical information that supports key points]\n",
        "\n",
        "        CONCLUSIONS/TAKEAWAYS:\n",
        "        • [What the reader should remember]\n",
        "\n",
        "        ACTION ITEMS (if applicable):\n",
        "        • [What should be done based on this content]\n",
        "        \"\"\"\n",
        "    }\n",
        "\n",
        "    if request_type == \"flowchart\":\n",
        "        return generate_flowchart(gemini_model, content)\n",
        "\n",
        "    prompt = prompts.get(request_type, prompts[\"explain\"])\n",
        "    return generate_granite_response(tokenizer, model, prompt, 1200)\n",
        "\n",
        "# Enhanced dynamic interface with real-time features\n",
        "def create_dynamic_interface():\n",
        "    # Global variables for models\n",
        "    global granite_tokenizer, granite_model, gemini_model, processing_state\n",
        "    granite_tokenizer, granite_model, gemini_model = None, None, None\n",
        "    processing_state = {\"is_processing\": False, \"current_task\": \"\"}\n",
        "\n",
        "    def initialize_system(api_key):\n",
        "        global granite_tokenizer, granite_model, gemini_model\n",
        "        if not api_key.strip():\n",
        "            return \"Please enter your Gemini API key\", gr.update(visible=False)\n",
        "\n",
        "        granite_tokenizer, granite_model, gemini_model, status = initialize_models(api_key)\n",
        "        models_ready = granite_model is not None\n",
        "        return status, gr.update(visible=models_ready)\n",
        "\n",
        "    def update_processing_status(is_processing, task=\"\"):\n",
        "        processing_state[\"is_processing\"] = is_processing\n",
        "        processing_state[\"current_task\"] = task\n",
        "        if is_processing:\n",
        "            return f\"Processing: {task}...\", gr.update(interactive=False)\n",
        "        else:\n",
        "            return \"Ready for new requests\", gr.update(interactive=True)\n",
        "\n",
        "    def handle_request(file, url, text_input, request_type, question, study_duration, learning_style, language, progress=gr.Progress()):\n",
        "        if granite_model is None:\n",
        "            return \"Please set up your API key first\", \"Ready\"\n",
        "\n",
        "        # Update processing status\n",
        "        task_names = {\n",
        "            \"explain\": \"Explaining content\",\n",
        "            \"questions\": \"Answering question\",\n",
        "            \"flowchart\": \"Creating flowchart\",\n",
        "            \"study_plan\": \"Building study plan\",\n",
        "            \"tutor\": \"Setting up virtual tutor\",\n",
        "            \"translate\": \"Translating content\",\n",
        "            \"tasks\": \"Organizing tasks\",\n",
        "            \"summarize\": \"Summarizing content\"\n",
        "        }\n",
        "\n",
        "        current_task = task_names.get(request_type, \"Processing request\")\n",
        "\n",
        "        # Simulate progress updates\n",
        "        progress(0.1, desc=\"Analyzing input...\")\n",
        "        time.sleep(0.5)\n",
        "\n",
        "        # Get content from file, URL, or text input\n",
        "        content = \"\"\n",
        "        if file is not None or url.strip():\n",
        "            progress(0.3, desc=\"Processing file/URL...\")\n",
        "            content = process_file(file, url)\n",
        "            time.sleep(0.5)\n",
        "        elif text_input.strip():\n",
        "            content = text_input.strip()\n",
        "\n",
        "        progress(0.5, desc=\"Preparing AI request...\")\n",
        "\n",
        "        # Handle different request types\n",
        "        additional_input = \"\"\n",
        "        if request_type == \"questions\":\n",
        "            additional_input = question\n",
        "        elif request_type == \"study_plan\":\n",
        "            additional_input = study_duration\n",
        "            content = text_input if text_input.strip() else \"General study topic\"\n",
        "        elif request_type == \"tutor\":\n",
        "            additional_input = learning_style\n",
        "        elif request_type == \"tasks\":\n",
        "            content = text_input if text_input.strip() else content\n",
        "\n",
        "        progress(0.7, desc=f\"{current_task}...\")\n",
        "\n",
        "        result = process_ai_request(\n",
        "            granite_tokenizer, granite_model, gemini_model,\n",
        "            content, request_type, additional_input, language\n",
        "        )\n",
        "\n",
        "        progress(1.0, desc=\"Complete!\")\n",
        "\n",
        "        return result, \"Ready for new requests\"\n",
        "\n",
        "    def get_content_preview(file, url, text_input):\n",
        "        \"\"\"Dynamic content preview\"\"\"\n",
        "        if file is not None:\n",
        "            return f\"File uploaded: {file.name} | Type: {file.name.split('.')[-1].upper()}\"\n",
        "        elif url.strip():\n",
        "            return f\"URL provided: {url[:50]}{'...' if len(url) > 50 else ''}\"\n",
        "        elif text_input.strip():\n",
        "            preview = text_input[:100]\n",
        "            return f\"Text input: {preview}{'...' if len(text_input) > 100 else ''}\"\n",
        "        else:\n",
        "            return \"No content provided yet\"\n",
        "\n",
        "    def update_button_states(request_type):\n",
        "        \"\"\"Update button appearances based on selection\"\"\"\n",
        "        button_configs = {}\n",
        "        for btn_type in [\"explain\", \"questions\", \"flowchart\", \"summarize\", \"study_plan\", \"tutor\", \"tasks\", \"translate\"]:\n",
        "            if btn_type == request_type:\n",
        "                button_configs[btn_type] = gr.update(variant=\"primary\")\n",
        "            else:\n",
        "                button_configs[btn_type] = gr.update(variant=\"secondary\")\n",
        "        return button_configs\n",
        "\n",
        "    # Enhanced CSS with animations and better responsiveness\n",
        "    custom_css = \"\"\"\n",
        "    .gradio-container {\n",
        "        font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif !important;\n",
        "        max-width: 1400px !important;\n",
        "        margin: 0 auto !important;\n",
        "    }\n",
        "    .main-header {\n",
        "        text-align: center;\n",
        "        padding: 2rem 1rem;\n",
        "        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "        color: white;\n",
        "        border-radius: 1rem;\n",
        "        margin-bottom: 2rem;\n",
        "        box-shadow: 0 4px 15px rgba(102, 126, 234, 0.3);\n",
        "    }\n",
        "    .content-preview {\n",
        "        background: #f8f9fa;\n",
        "        border: 1px solid #dee2e6;\n",
        "        border-radius: 0.5rem;\n",
        "        padding: 0.75rem;\n",
        "        margin: 0.5rem 0;\n",
        "        font-size: 0.9rem;\n",
        "        color: #6c757d;\n",
        "    }\n",
        "    .status-indicator {\n",
        "        padding: 0.5rem 1rem;\n",
        "        border-radius: 0.375rem;\n",
        "        text-align: center;\n",
        "        font-weight: 500;\n",
        "        margin: 0.5rem 0;\n",
        "        transition: all 0.3s ease;\n",
        "    }\n",
        "    .status-ready {\n",
        "        background: #d1edff;\n",
        "        color: #0969da;\n",
        "        border: 1px solid #54aeff;\n",
        "    }\n",
        "    .status-processing {\n",
        "        background: #fff8dc;\n",
        "        color: #9a6700;\n",
        "        border: 1px solid #d4ac0d;\n",
        "    }\n",
        "    .quick-action-btn {\n",
        "        margin: 0.25rem;\n",
        "        min-height: 2.5rem !important;\n",
        "        border-radius: 0.5rem !important;\n",
        "        font-weight: 500 !important;\n",
        "        transition: all 0.2s ease !important;\n",
        "    }\n",
        "    .quick-action-btn:hover {\n",
        "        transform: translateY(-1px);\n",
        "        box-shadow: 0 2px 8px rgba(0,0,0,0.15);\n",
        "    }\n",
        "    .results-container {\n",
        "        border: 1px solid #e1e5e9;\n",
        "        border-radius: 0.75rem;\n",
        "        background: #ffffff;\n",
        "        box-shadow: 0 2px 4px rgba(0,0,0,0.05);\n",
        "    }\n",
        "    @media (max-width: 768px) {\n",
        "        .main-header h1 { font-size: 1.5rem; }\n",
        "        .quick-action-btn { min-height: 3rem !important; font-size: 0.9rem; }\n",
        "    }\n",
        "    \"\"\"\n",
        "\n",
        "    with gr.Blocks(css=custom_css, title=\"Edututor-AI Learning Assistant\") as app:\n",
        "\n",
        "        # Header\n",
        "        gr.HTML(\"\"\"\n",
        "        <div class=\"main-header\">\n",
        "            <h1>Edututor</h1>\n",
        "            <p>Powered by IBM Granite and gemini's nano banana</p>\n",
        "            <p>Upload → Ask → Learn | Simple, Fast, Smart</p>\n",
        "        </div>\n",
        "        \"\"\")\n",
        "\n",
        "        # Setup section with better feedback\n",
        "        with gr.Accordion(\"Setup (Click to expand)\", open=False):\n",
        "            gr.Markdown(\"### Get your free API key from [Google AI Studio](https://aistudio.google.com/app/apikey)\")\n",
        "            with gr.Row():\n",
        "                api_key = gr.Textbox(\n",
        "                    label=\"Gemini API Key\",\n",
        "                    type=\"password\",\n",
        "                    placeholder=\"Enter your API key here...\",\n",
        "                    scale=3\n",
        "                )\n",
        "                setup_btn = gr.Button(\"Initialize\", variant=\"primary\", scale=1)\n",
        "\n",
        "            setup_status = gr.Textbox(label=\"Status\", interactive=False, show_label=False)\n",
        "\n",
        "        # Main interface (initially hidden until setup)\n",
        "        main_interface = gr.Column(visible=False)\n",
        "\n",
        "        with main_interface:\n",
        "            # Dynamic status indicator\n",
        "            status_display = gr.HTML(\n",
        "                '<div class=\"status-indicator status-ready\">Ready for new requests</div>',\n",
        "                visible=True\n",
        "            )\n",
        "\n",
        "            # Content input section\n",
        "            gr.Markdown(\"## Add Your Content\")\n",
        "\n",
        "            with gr.Row():\n",
        "                with gr.Column(scale=2):\n",
        "                    file_input = gr.File(\n",
        "                        label=\"Upload File\",\n",
        "                        file_types=[\".pdf\", \".pptx\", \".txt\"],\n",
        "                        height=100\n",
        "                    )\n",
        "                with gr.Column(scale=2):\n",
        "                    url_input = gr.Textbox(\n",
        "                        label=\"Or Paste URL\",\n",
        "                        placeholder=\"https://example.com/article\",\n",
        "                        lines=1\n",
        "                    )\n",
        "\n",
        "            text_input = gr.Textbox(\n",
        "                label=\"Or Type/Paste Text Directly\",\n",
        "                placeholder=\"Enter your content, question, or topic here...\",\n",
        "                lines=3\n",
        "            )\n",
        "\n",
        "            # Dynamic content preview\n",
        "            content_preview = gr.HTML(\n",
        "                '<div class=\"content-preview\">No content provided yet</div>'\n",
        "            )\n",
        "\n",
        "            # Action buttons with enhanced layout\n",
        "            gr.Markdown(\"## What would you like to do?\")\n",
        "\n",
        "            with gr.Row():\n",
        "                explain_btn = gr.Button(\"Explain Simply\", variant=\"secondary\", size=\"lg\")\n",
        "                questions_btn = gr.Button(\"Ask Questions\", variant=\"secondary\", size=\"lg\")\n",
        "                flowchart_btn = gr.Button(\"Create Flowchart\", variant=\"secondary\", size=\"lg\")\n",
        "                summarize_btn = gr.Button(\"Summarize\", variant=\"secondary\", size=\"lg\")\n",
        "\n",
        "            with gr.Row():\n",
        "                study_btn = gr.Button(\"Study Plan\", variant=\"secondary\", size=\"lg\")\n",
        "                tutor_btn = gr.Button(\"Get Tutor\", variant=\"secondary\", size=\"lg\")\n",
        "                tasks_btn = gr.Button(\"Organize Tasks\", variant=\"secondary\", size=\"lg\")\n",
        "                translate_btn = gr.Button(\"Translate\", variant=\"secondary\", size=\"lg\")\n",
        "\n",
        "            # Dynamic options with better styling\n",
        "            with gr.Group():\n",
        "                question_input = gr.Textbox(\n",
        "                    label=\"Your Question\",\n",
        "                    placeholder=\"What would you like to know?\",\n",
        "                    visible=False,\n",
        "                    lines=2\n",
        "                )\n",
        "\n",
        "                study_duration = gr.Dropdown(\n",
        "                    choices=[\"1 week\", \"2 weeks\", \"1 month\", \"3 months\", \"6 months\"],\n",
        "                    label=\"Study Duration\",\n",
        "                    value=\"1 month\",\n",
        "                    visible=False\n",
        "                )\n",
        "\n",
        "                learning_style = gr.Dropdown(\n",
        "                    choices=[\"Visual Learner\", \"Step-by-step\", \"Quick Overview\", \"Detailed Explanation\", \"Interactive\", \"Problem-solving\"],\n",
        "                    label=\"Learning Style\",\n",
        "                    value=\"Step-by-step\",\n",
        "                    visible=False\n",
        "                )\n",
        "\n",
        "                language_select = gr.Dropdown(\n",
        "                    choices=[\"Spanish\", \"French\", \"German\", \"Hindi\", \"Tamil\", \"Chinese\", \"Japanese\", \"Portuguese\", \"Italian\", \"Russian\", \"Arabic\"],\n",
        "                    label=\"Target Language\",\n",
        "                    value=\"Spanish\",\n",
        "                    visible=False\n",
        "                )\n",
        "\n",
        "            # Results area with enhanced styling\n",
        "            gr.Markdown(\"## Results\")\n",
        "            output_area = gr.Textbox(\n",
        "                label=\"AI Response\",\n",
        "                lines=15,\n",
        "                max_lines=30,\n",
        "                show_copy_button=True,\n",
        "                placeholder=\"Your results will appear here...\",\n",
        "                elem_classes=[\"results-container\"]\n",
        "            )\n",
        "\n",
        "        # Hidden state management\n",
        "        current_mode = gr.State(\"explain\")\n",
        "\n",
        "        # Setup button functionality\n",
        "        setup_btn.click(\n",
        "            initialize_system,\n",
        "            inputs=[api_key],\n",
        "            outputs=[setup_status, main_interface]\n",
        "        )\n",
        "\n",
        "        # Dynamic content preview updates\n",
        "        for input_component in [file_input, url_input, text_input]:\n",
        "            input_component.change(\n",
        "                lambda f, u, t: f'<div class=\"content-preview\">{get_content_preview(f, u, t)}</div>',\n",
        "                inputs=[file_input, url_input, text_input],\n",
        "                outputs=[content_preview]\n",
        "            )\n",
        "\n",
        "        # Enhanced mode switching functions\n",
        "        def show_question_mode():\n",
        "            return (\n",
        "                gr.update(visible=True), gr.update(visible=False),\n",
        "                gr.update(visible=False), gr.update(visible=False),\n",
        "                \"questions\"\n",
        "            )\n",
        "\n",
        "        def show_study_mode():\n",
        "            return (\n",
        "                gr.update(visible=False), gr.update(visible=True),\n",
        "                gr.update(visible=False), gr.update(visible=False),\n",
        "                \"study_plan\"\n",
        "            )\n",
        "\n",
        "        def show_tutor_mode():\n",
        "            return (\n",
        "                gr.update(visible=False), gr.update(visible=False),\n",
        "                gr.update(visible=True), gr.update(visible=False),\n",
        "                \"tutor\"\n",
        "            )\n",
        "\n",
        "        def show_translate_mode():\n",
        "            return (\n",
        "                gr.update(visible=False), gr.update(visible=False),\n",
        "                gr.update(visible=False), gr.update(visible=True),\n",
        "                \"translate\"\n",
        "            )\n",
        "\n",
        "        def hide_all_options(mode):\n",
        "            return (\n",
        "                gr.update(visible=False), gr.update(visible=False),\n",
        "                gr.update(visible=False), gr.update(visible=False),\n",
        "                mode\n",
        "            )\n",
        "\n",
        "        # Button click events\n",
        "        questions_btn.click(\n",
        "            show_question_mode,\n",
        "            outputs=[question_input, study_duration, learning_style, language_select, current_mode]\n",
        "        )\n",
        "\n",
        "        study_btn.click(\n",
        "            show_study_mode,\n",
        "            outputs=[question_input, study_duration, learning_style, language_select, current_mode]\n",
        "        )\n",
        "\n",
        "        tutor_btn.click(\n",
        "            show_tutor_mode,\n",
        "            outputs=[question_input, study_duration, learning_style, language_select, current_mode]\n",
        "        )\n",
        "\n",
        "        translate_btn.click(\n",
        "            show_translate_mode,\n",
        "            outputs=[question_input, study_duration, learning_style, language_select, current_mode]\n",
        "        )\n",
        "\n",
        "        for btn, mode in [\n",
        "            (explain_btn, \"explain\"), (flowchart_btn, \"flowchart\"),\n",
        "            (summarize_btn, \"summarize\"), (tasks_btn, \"tasks\")\n",
        "        ]:\n",
        "            btn.click(\n",
        "                lambda m=mode: hide_all_options(m),\n",
        "                outputs=[question_input, study_duration, learning_style, language_select, current_mode]\n",
        "            )\n",
        "\n",
        "        # Main processing with progress tracking\n",
        "        all_inputs = [file_input, url_input, text_input, current_mode, question_input, study_duration, learning_style, language_select]\n",
        "\n",
        "        for btn in [explain_btn, questions_btn, flowchart_btn, summarize_btn, study_btn, tutor_btn, tasks_btn, translate_btn]:\n",
        "            btn.click(\n",
        "                handle_request,\n",
        "                inputs=all_inputs,\n",
        "                outputs=[output_area, status_display],\n",
        "                show_progress=\"full\"\n",
        "            )\n",
        "\n",
        "        # Help section\n",
        "        with gr.Accordion(\"Quick Help & Tips\", open=False):\n",
        "            gr.Markdown(\"\"\"\n",
        "            ### How to use:\n",
        "            1. **Setup**: Enter your Gemini API key (one-time setup)\n",
        "            2. **Add Content**: Upload file, paste URL, or type directly\n",
        "            3. **Choose Action**: Click any button for desired function\n",
        "            4. **Get Results**: Watch progress and receive AI response\n",
        "\n",
        "            ### Pro Tips:\n",
        "            - **File Support**: PDF, PowerPoint, Text files up to 50MB\n",
        "            - **URL Support**: Articles, blogs, documentation pages\n",
        "            - **Languages**: 11+ languages for translation\n",
        "            - **Progress**: Real-time progress tracking for all operations\n",
        "            - **Copy Results**: Use copy button to save responses\n",
        "\n",
        "            ### Device Info:\n",
        "            - **GPU Available**: Faster processing with CUDA support\n",
        "            - **CPU Fallback**: Works on any system configuration\n",
        "\n",
        "            **Get API Key**: Free at [Google AI Studio](https://aistudio.google.com/app/apikey)\n",
        "            \"\"\")\n",
        "\n",
        "    return app\n",
        "\n",
        "# Launch the application\n",
        "if __name__ == \"__main__\":\n",
        "    app = create_dynamic_interface()\n",
        "    app.launch(\n",
        "        debug=True,\n",
        "        share=True,\n",
        "        server_name=\"0.0.0.0\",\n",
        "        server_port=7860,\n",
        "        show_error=True,\n",
        "        inbrowser=True\n",
        "    )"
      ],
      "metadata": {
        "id": "RDQDRhz2oIm0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}